<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>opencv_python</title>
</head>
<body><h1 id='一计算机眼中的图像'>一.计算机眼中的图像</h1>
<h2 id='图像基本操作'>图像基本操作</h2>
<p>&nbsp;</p>
<h3 id='数据读取-图像'>数据读取-图像</h3>
<ul>
<li>cv2.IMREAD_COLOR ：彩色图像</li>
<li>cv2.IMREAD_GRAYSCALE：灰度图像</li>

</ul>
<p>&nbsp;</p>
<pre><code class='language-python' lang='python'>import cv2 

img=cv2.imread(&quot;C://Users//Lenovo//Desktop//swxg.jpg&quot;)
print(img)
</code></pre>
<p>&nbsp;</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240115183052746.png" referrerpolicy="no-referrer" alt="image-20240115183052746"></p>
<h3 id='图像的显示'>图像的显示</h3>
<pre><code class='language-python' lang='python'>import cv2 #opencv读取的格式是BGR

img=cv2.imread(&quot;C://Users//Lenovo//Desktop//swxg.jpg&quot;)
cv2.imshow(&quot;image&quot;,img)
cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240115183256870.png" referrerpolicy="no-referrer" alt="image-20240115183256870"></p>
<pre><code class='language-python' lang='python'>import cv2 

def cv_show(name,img):
    cv2.imshow(&quot;image&quot;,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C://Users//Lenovo//Desktop//swxg.jpg&quot;)
img1=cv2.imread(&quot;C://Users//Lenovo//Desktop//swxg.jpg&quot;,cv2.IMREAD_GRAYSCALE)
cv_show(&quot;image&quot;,img)
cv_show(&quot;image&quot;,img1)
</code></pre>
<p>&nbsp;</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240115184540377.png" referrerpolicy="no-referrer" alt="image-20240115184540377"></p>
<p>灰度图只有一个颜色通道，所以打印出的shape的值只有高和宽两个参数</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240115184711613.png" referrerpolicy="no-referrer" alt="image-20240115184711613"></p>
<h1 id='二视频的读取与处理'>二.视频的读取与处理</h1>
<h2 id='数据读取-视频'>数据读取-视频</h2>
<ul>
<li>cv2.VideoCapture既可以用于视频也可以用于摄像头，如果是视频那就加上文件的路径，如果是摄像头那就用摄像头的参数，-1,0,1，或者是其在linux系统的/dev文件夹下面的地址(纯是我的经验之谈)</li>
<li></li>

</ul>
<pre><code class='language-python' lang='python'>import cv2  

vc = cv2.VideoCapture(&quot;D:/VIDEO_CAPTURE/Desktop/Desktop 2023.11.29 - 19.21.30.01.mp4&quot;)

if vc.isOpened():
    open, frame = vc.read()
else:
    open = False

while open:
    ret, frame = vc.read()
    if frame is None:
        break
    if ret == True:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGRA2GRAY)
        cv2.imshow(&#39;result&#39;, gray)
        if cv2.waitKey(10) &amp; 0xFF == 27:
            break
vc.release()
cv2.destroyAllWindows()
</code></pre>
<p>&nbsp;</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116182042724.png" referrerpolicy="no-referrer" alt="image-20240116182042724"></p>
<h1 id='三roi区域'>三.ROI区域</h1>
<h2 id='截取部分图像数据'>截取部分图像数据</h2>
<pre><code class='language-python' lang='python'>import cv2

def cv_show(name,img):
    cv2.imshow(&quot;image&quot;,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C://Users//Lenovo//Desktop//swxg.jpg&quot;)
muscle=img[500:1000,0:1000]
cv_show(&quot;image&quot;,muscle)
</code></pre>
<p>&nbsp;</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116182606027.png" referrerpolicy="no-referrer" alt="image-20240116182606027"></p>
<p>&nbsp;</p>
<h2 id='颜色通道提取'>颜色通道提取</h2>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116183418955.png" referrerpolicy="no-referrer" alt="image-20240116183418955"></p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116183429506.png" referrerpolicy="no-referrer" alt="image-20240116183429506"></p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116183436392.png" referrerpolicy="no-referrer" alt="image-20240116183436392"></p>
<pre><code class='language-python' lang='python'>import cv2

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C://Users//Lenovo//Desktop//swxg.jpg&quot;)
muscle=img[500:1000,0:1000]
b,g,r=cv2.split(muscle)
cv_show(&quot;b&quot;,b)
cv_show(&quot;r&quot;,r)
cv_show(&quot;g&quot;,g)
</code></pre>
<p>注意:opencv读取的格式是BGR,而不是RGB,顺序不能错，因为返回的值分别是B/G/R</p>
<p>由于索引是BGR,则B为0，G为1，R为2，一一对应</p>
<p>如果只保留R</p>
<pre><code class='language-python' lang='python'>img=img.copy()
img[:,:,0]=0
img[:,:,1]=0
cv_show(&#39;R&#39;,img)
</code></pre>
<p>同理，那么只保留G就让第三个参数的0和2为0，只保留B就是让第三个参数的1和2都为0</p>
<h2 id='颜色通道合并'>颜色通道合并</h2>
<pre><code class='language-python' lang='python'>import cv2

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C://Users//Lenovo//Desktop//swxg.jpg&quot;)
muscle=img[500:1000,0:1000]
b,g,r=cv2.split(muscle)
cv_show(&quot;b&quot;,b)
cv_show(&quot;r&quot;,r)
cv_show(&quot;g&quot;,g)
newimg=cv2.merge((b,g,r))
cv_show(&quot;newimg&quot;,newimg)
</code></pre>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116183909983.png" referrerpolicy="no-referrer" alt="image-20240116183909983"></p>
<h1 id='四边界填充'>四.边界填充</h1>
<ul>
<li>复制法，BORDER_REPLICATE，复制最边缘像素</li>
<li>反射法，BORDER_REFLECT，对感兴趣的图像中的像素在两边进行</li>
<li>反射法，BORDER_REFLECT_101，以最边缘的像素为轴，对称</li>
<li>外包装法，BORDER_WRAP</li>
<li>常量法，BORDER_CONSTANT,常数值填充</li>

</ul>
<pre><code class='language-python' lang='python'>import cv2
import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C://Users//Lenovo//Desktop//swxg.jpg&quot;)

top_size,bottom_size,left_size,right_size=(50,50,50,50)

replicate=cv2.copyMakeBorder(img,top_size,bottom_size,left_size,right_size,borderType=cv2.BORDER_REPLICATE)
reflect=cv2.copyMakeBorder(img,top_size,bottom_size,left_size,right_size,borderType=cv2.BORDER_REFLECT)
reflect101=cv2.copyMakeBorder(img,top_size,bottom_size,left_size,right_size,borderType=cv2.BORDER_REFLECT101)
wrap=cv2.copyMakeBorder(img,top_size,bottom_size,left_size,right_size,borderType=cv2.BORDER_WRAP)
constant=cv2.copyMakeBorder(img,top_size,bottom_size,left_size,right_size,borderType=cv2.BORDER_CONSTANT)

plt.subplot(231),plt.imshow(img,&#39;gray&#39;),plt.title(&#39;ORIGINAL&#39;)
plt.subplot(232),plt.imshow(replicate,&#39;gray&#39;),plt.title(&#39;REPLICATE&#39;)
plt.subplot(233),plt.imshow(reflect,&#39;gray&#39;),plt.title(&#39;REFLECT&#39;)
plt.subplot(234),plt.imshow(reflect101,&#39;gray&#39;),plt.title(&#39;OREFLECT001&#39;)
plt.subplot(235),plt.imshow(wrap,&#39;gray&#39;),plt.title(&#39;WRAP&#39;)
plt.subplot(236),plt.imshow(constant,&#39;gray&#39;),plt.title(&#39;CONSTANT&#39;)
plt.show()
</code></pre>
<p>&nbsp;</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116193248252.png" referrerpolicy="no-referrer" alt="image-20240116193248252"></p>
<h1 id='五数值计算'>五.数值计算</h1>
<h2 id='两种计算方法'>两种计算方法</h2>
<ul>
<li>用+进行运算，如果超出0-255会用256进行取余</li>
<li>如果使用cv2.add，超出的部分都是255，根据RGB颜色模型将0-1映射为0-255，低于0全部变成黑色，高于255全部变成白色</li>

</ul>
<h2 id='融合图像'>融合图像</h2>
<p>融合图像要求两个图像的shape值相同，所以要对图像做一个resize操作以满足shape值相同这一重要条件</p>
<pre><code class='language-python' lang='python'>import cv2
import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img1=cv2.imread(&quot;C://Users//Lenovo//Desktop//swxg.jpg&quot;)
img2=cv2.imread(&quot;C://Users//Lenovo//Desktop//kls.png&quot;)

img1_resized = cv2.resize(img1, (img2.shape[1], img2.shape[0]))

res = cv2.addWeighted(img1_resized, 0.5, img2, 0.5, 0)

plt.imshow(res)
plt.show()
</code></pre>
<p>这里的addweight函数就是用于融合图像的，第一个和第三个参数都是图像，图像后面紧跟着的是他们的权值比例，最后一个是偏置量，整个公式可以表达为</p>
<p>Result=alpha×x1+beta×x2+gamma</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116203055387.png" referrerpolicy="no-referrer" alt="image-20240116203055387"></p>
<h2 id='按比例放缩图像'>按比例放缩图像</h2>
<pre><code class='language-python' lang='python'>res=cv2.resize(img,0,0,fx=1,fy=3)
</code></pre>
<p>也就是说参数处我们可以选择填一个0，然后直接用比例缩放的形式达到裁剪图像的效果，比方说把x轴，也就是宽度，这里给压缩到了原来的三分之一</p>
<h1 id='六图像阈值'>六.图像阈值</h1>
<pre><code class='language-python' lang='python'>res,dst=cv2.threshold(src,threshmmaxval,type)
</code></pre>
<ul>
<li><p>src:输入图，只能输入单通道的图像，就是灰度图</p>
</li>
<li><p>dst:输出图</p>
</li>
<li><p>thresh:阈值</p>
</li>
<li><p>maxval:当像素超过了阈值(或者小于阈值，这个看type)，所赋予的值</p>
</li>
<li><p>type:二值化操作的类型，包含以下五种类型</p>
<ul>
<li>cv2.THRESH_BINARY 超过阈值部分取maxval,否则取0</li>
<li>cv2.THRESH_BINARY_INV，就是上面的反转</li>
<li>cv2.THRESH_TRUNC,大于阈值部分设为阈值，否则不变</li>
<li>cv2.THRESH_TOZERO,大于阈值部分不改变，否则设为0</li>
<li>cv2.THRESH_TOZERO_INV，就是上面的反转</li>

</ul>
</li>

</ul>
<pre><code class='language-python' lang='python'>import cv2
import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img1=cv2.imread(&quot;C://Users//Lenovo//Desktop//swxg.jpg&quot;)
img2=cv2.imread(&quot;C://Users//Lenovo//Desktop//kls.png&quot;)

blue,gray,red=cv2.split(img1)
ret,thresh1=cv2.threshold(gray,127,255,cv2.THRESH_BINARY)
ret,thresh2=cv2.threshold(gray,127,255,cv2.THRESH_BINARY_INV)
ret,thresh3=cv2.threshold(gray,127,255,cv2.THRESH_TRUNC)
ret,thresh4=cv2.threshold(gray,127,255,cv2.THRESH_TOZERO)
ret,thresh5=cv2.threshold(gray,127,255,cv2.THRESH_TOZERO_INV)

titles=[&#39;origin&#39;,&#39;Binary&#39;,&#39;Binary_Inv&#39;,&#39;Thresh_Trunc&#39;,&#39;Thresh_ToZero&#39;,&#39;Thresh_ToZero_Inv&#39;]
images=[img1,thresh1,thresh2,thresh3,thresh4,thresh5]

for i in range(6):
    plt.subplot(2,3,i+1),plt.imshow(images[i],&#39;gray&#39;)
    plt.title(titles[i])
    plt.xticks([]),plt.yticks([])

plt.show()
</code></pre>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116211112252.png" referrerpolicy="no-referrer" alt="image-20240116211112252"></p>
<h1 id='七图像平滑'>七.图像平滑</h1>
<p>图像平滑需要用到滤波操作，所谓滤波其实就是在图像矩阵上面做卷积处理。</p>
<h2 id='1均值滤波'>1.均值滤波</h2>
<p>先选取一个矩阵，比如说图像中每次选3*3的，对这九个元素取平均值，就是均值滤波，这是一种简单的平均卷积操作</p>
<p>因为我懒得给他们加噪点了，这里就用Lena女神的经典照片处理了，可以看到这是一个有噪点的图像</p>
<p><img src="C:\Users\Lenovo\Desktop\lena.png" referrerpolicy="no-referrer" alt="image-20240116212438718"></p>
<p>这是处理过后的</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116212808694.png" referrerpolicy="no-referrer" alt="image-20240116212808694"></p>
<p>可以看到降噪效果还是有的</p>
<pre><code class='language-python' lang='python'>import cv2
# import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/lena.png&quot;)
blur=cv2.blur(img,(3,3))
cv_show(&#39;blur&#39;,blur)
</code></pre>
<p>&nbsp;</p>
<h2 id='2方框滤波'>2.方框滤波</h2>
<p>基本是和均值一样的，可以选择归一化,这个时候就是和均值滤波是一样的。如果不选择归一化可能会导致超出255，然后几乎就全白了，因为这样很容易越界</p>
<p>&nbsp;</p>
<h2 id='3高斯滤波'>3.高斯滤波</h2>
<p>高斯滤波的卷积核里面的数值是满足高斯分布，相当于更重视中间的，可以理解为把总的的权重加起来设置成1，然后靠得近的权值也设置的比较大，离得远就设置的小一点，表示重要性小一点。</p>
<p>高斯分布长得有点像正态分布</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116215613055.png" referrerpolicy="no-referrer" alt="image-20240116215613055"></p>
<p>这下图像处理的就更干净一点点，当然可以继续调整参数了，我这里把sigmaX又从1设置成了3</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116220152113.png" referrerpolicy="no-referrer" alt="image-20240116220152113"></p>
<pre><code class='language-python' lang='python'>import cv2
# import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/lena.png&quot;)
aussian=cv2.GaussianBlur(img,(5,5),1)
cv_show(&#39;aussian&#39;,aussian)

</code></pre>
<p>其实最完整的函数重载版本是这样的</p>
<pre><code class='language-python' lang='python'>cv2.GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY[, borderType]]])
</code></pre>
<p>这里的第二个参数是卷积核的大小，第三个就是X方向上面的标准差，第四个是输出图像，第五个是Y方向上的标准差，第六个是像素外插值的边界类型，只有src和ksize是必选的</p>
<h2 id='4中值滤波'>4.中值滤波</h2>
<p>相当于直接用中值来代替了</p>
<p>比如说九个数字，先排序，然后选择第五个数字</p>
<p>处理完的图像是这样的</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116220506868.png" referrerpolicy="no-referrer" alt="image-20240116220506868"></p>
<p>个人感觉这张是所有滤波里面处理的最好的，达到了还原度和降噪效果的均衡。</p>
<p>然后我把中值滤波的ksize从5改到7，就发现图像有点失真了，然后调到3噪点又太多了，说明刚刚那个其实已经是最佳参数了</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116220604010.png" referrerpolicy="no-referrer" alt="image-20240116220604010"></p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116220700262.png" referrerpolicy="no-referrer" alt="image-20240116220700262"></p>
<p>当然日常开发要是没闲工夫一个个对比可以直接把图片全部展示出来，这样就把几个图像横着拼在一块了，也可以用vstack竖着拼</p>
<pre><code class='language-python' lang='python'>res=np.hstack(blur,aussian,medain)
cv2.imshow(&quot;res&quot;,res)
</code></pre>
<h1 id='八形态学腐蚀膨胀'>八.形态学腐蚀膨胀</h1>
<h2 id='1腐蚀'>1.腐蚀</h2>
<p>腐蚀就是清理掉一些东西，把图像往里面缩,基本是用于二值化图像的。就可以理解有一个苹果，上面有微生物正在啃食苹果，那我们如果实在没东西吃了必须吃这个苹果，那就得切割下来被腐蚀的部分，也就是说在图像边界区域的一个矩阵，里面元素都是1，但是里面出现了0，那这个矩阵也可以理解为被腐蚀掉了</p>
<p>这是原图像</p>
<p><img src="C:\Users\Lenovo\Desktop\cmx.jpg" referrerpolicy="no-referrer" alt="cmx"></p>
<p>这是灰度图gray</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116222224478.png" referrerpolicy="no-referrer" alt="image-20240116222224478"></p>
<p>这是腐蚀过后的</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116222239730.png" referrerpolicy="no-referrer" alt="image-20240116222239730"></p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np
# import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/cmx.jpg&quot;)
b,r,g=cv2.split(img)

kernel=np.ones((5,5),np.uint8)
erosion=cv2.erode(g,kernel,iterations=1)

cv_show(&quot;gray&quot;,g)
cv_show(&quot;erosion&quot;,erosion)
</code></pre>
<p>那既然是微生物分解苹果，可以分时期看这个事情。就比方说隔一个星期这个苹果又有多少部分不能吃了。腐蚀完成之后，所有元素假设都从1变0表示被腐蚀掉了，那为什么不能再腐蚀几个星期呢。这个叫做腐蚀的迭代，上面的程序里面的迭代次数就是1。每次迭代都从上一次腐蚀的结果中再次腐蚀。</p>
<p>那这里把迭代次数改成2就是这样的了</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116223856173.png" referrerpolicy="no-referrer" alt="image-20240116223856173"></p>
<p>再腐蚀感觉这个倒三角边缘的线条都要没了</p>
<p>这个参数中卷积核大小是很重要的，越大的核，每一次迭代发生的变化肯定就越大，比如说3*3的核，里面有一个是0就被腐蚀，如果是5×5的，它就要求25个里面不能有0才不会被腐蚀，所以在边缘的地方，你选择的卷积核越大肯定腐蚀的范围就越多了。</p>
<h2 id='2膨胀操作'>2.膨胀操作</h2>
<p>膨胀就是腐蚀的逆过程，逆运算</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116231316524.png" referrerpolicy="no-referrer" alt="image-20240116231316524"></p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116231248433.png" referrerpolicy="no-referrer" alt="image-20240116231248433"></p>
<p>可以看到腐蚀一次之后再膨胀一次，虽然和原图还是有比较大的差距，但是感觉恢复了一点。这个膨胀的意义很多时候其实是，腐蚀的时候把原图像给损失了，为了弥补这个损失对腐蚀后的图像再膨胀一遍。</p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np
# import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/cmx.jpg&quot;)
b,r,g=cv2.split(img)

kernel=np.ones((5,5),np.uint8)
erosion=cv2.erode(g,kernel,iterations=1)
cmx_dilate=cv2.dilate(erosion,kernel,iterations=1)

cv_show(&quot;gray&quot;,g)
cv_show(&quot;erosion&quot;,erosion)
cv_show(&quot;dilate&quot;,cmx_dilate)
</code></pre>
<h2 id='3开运算和闭运算'>3.开运算和闭运算</h2>
<p>开运算也就是先进行腐蚀再进行膨胀，也就是上面的过程</p>
<p>闭运算就是先膨胀再腐蚀</p>
<p>opencv里面甚至还对开闭运算做了一个完整封装函数，也就是形态学函数</p>
<p>开运算</p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np
# import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/cmx.jpg&quot;)
b,r,g=cv2.split(img)

kernel=np.ones((5,5),np.uint8)
opening=cv2.morphologyEx(g,cv2.MORPH_OPEN,kernel)
cv_show(&quot;openging&quot;,opening)
</code></pre>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116232201790.png" referrerpolicy="no-referrer"></p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np
# import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/cmx.jpg&quot;)
b,r,g=cv2.split(img)

kernel=np.ones((5,5),np.uint8)
opening=cv2.morphologyEx(g,cv2.MORPH_OPEN,kernel)
cv_show(&quot;openging&quot;,opening)
</code></pre>
<p>闭运算</p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np
# import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/cmx.jpg&quot;)
b,r,g=cv2.split(img)

kernel=np.ones((5,5),np.uint8)
closing=cv2.morphologyEx(g,cv2.MORPH_CLOSE,kernel)
cv_show(&quot;closing&quot;,closing)
</code></pre>
<p>&nbsp;</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116232300302.png" referrerpolicy="no-referrer" alt="image-20240116232300302"></p>
<p>开运算就比较适合取出小亮区域，让物体边缘平滑，保证边缘的清晰，闭运算经常用来连接断开的区域，填充小的黑色区域，平滑物体的边缘，就是用来保持物体的连续性的，可以填充小的空洞。</p>
<h2 id='4梯度运算'>4.梯度运算</h2>
<p>其实就是膨胀-腐蚀，也就是概率论中的（A-B），当然B属于A，因为膨胀的比腐蚀的大。就好比一个同心圆吧，用外面的减去里面的部分，让里面的变成黑的，剩下的白色的就是边界轮廓了。</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116233447447.png" referrerpolicy="no-referrer" alt="image-20240116233447447"></p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116233455399.png" referrerpolicy="no-referrer" alt="image-20240116233455399"></p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np
# import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/cmx.jpg&quot;)
b,r,g=cv2.split(img)

kernel=np.ones((5,5),np.uint8)
dilate=cv2.dilate(g,kernel,iterations=5)
erosion=cv2.erode(g,kernel,iterations=5)

res=np.hstack((dilate,erosion))

gradient=cv2.morphologyEx(g,cv2.MORPH_GRADIENT,kernel)

cv_show(&#39;res&#39;,res)
cv_show(&#39;gradient&#39;,gradient)
</code></pre>
<h2 id='5礼帽和黑帽'>5.礼帽和黑帽</h2>
<ul>
<li>礼帽：原始输入-开运算结果</li>
<li>黑帽：闭运算-原始输入</li>

</ul>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240116234132115.png" referrerpolicy="no-referrer" alt="image-20240116234132115"></p>
<p>左边是礼帽右边是黑帽</p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np
# import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/cmx.jpg&quot;)
g= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

kernel=np.ones((5,5),np.uint8)
tophat=cv2.morphologyEx(g,cv2.MORPH_TOPHAT,kernel)
blackhat=cv2.morphologyEx(g,cv2.MORPH_BLACKHAT,kernel)

res=np.hstack((tophat,blackhat))

cv_show(&#39;res&#39;,res)

</code></pre>
<p>白帽可以获得原图中灰度比较亮的区域</p>
<p>黑帽可以获得原图中灰度比较暗的区域</p>
<h1 id='九图像梯度算子'>九.图像梯度算子</h1>
<h2 id='1sobel算子'>1.Sobel算子</h2>
<p>图像区域要分为两个方向算，一个是Gx方向一个是Gy方向的，对于Gx矩阵，只需要把矩阵中的每个元素与一个权重矩阵中的元素对应相乘就行了，这个权重矩阵有点像是高斯分布的矩阵，离得越近权重越大，离得越远权重越小，区别就是一般来说用右边减去左边，因为矩阵右边都是大于0的，矩阵左边都是小于0的，矩阵中间是0，Gy计算也是一样的，用矩阵的下面减去上面。</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240117001122761.png" referrerpolicy="no-referrer" alt="image-20240117001122761"></p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240117005234136.png" referrerpolicy="no-referrer" alt="image-20240117005234136"></p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np
# import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/cmx.jpg&quot;)
g= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

sobelx=cv2.Sobel(g,cv2.CV_64F,1,0,ksize=3)
#要知道这样很可能算出负的值，即使会截断，它本质上也是负值，如果不转换，当右边是黑色，左边是白色，因为是用右边减去左边算的，黑到白是负数，所有负数都会被截断成0,就导致右边的白色区域会显示不出来
sobelx=cv2.convertScaleAbs(sobelx)
sobely=cv2.Sobel(g,cv2.CV_64F,0,1,ksize=3)
sobely=cv2.convertScaleAbs(sobely)

cv_show(&#39;sobelx&#39;,sobelx)
cv_show(&#39;sobley&#39;,sobely)

</code></pre>
<p>&nbsp;</p>
<h2 id='2梯度计算方法'>2.梯度计算方法</h2>
<p>这个G有很多种算法</p>
<p>比如说G=根号下Gx²+Gy²</p>
<p>又或者是G=|G1x|+|G2y|</p>
<p>一般来说是不建议直接计算xy的，效果是不太好的，会出现重影和模糊，而是分别计算x和y再进行求和，因为有一个addWeighted的这样的一个计算权重的函数</p>
<p>&nbsp;</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240117005257809.png" referrerpolicy="no-referrer" alt="image-20240117005257809"></p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np
# import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/cmx.jpg&quot;)
g= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

sobelx=cv2.Sobel(g,cv2.CV_64F,1,0,ksize=3)
#要知道这样很可能算出负的值，即使会截断，它本质上也是负值，还是转化成绝对值来的比较好
sobelx=cv2.convertScaleAbs(sobelx)
sobely=cv2.Sobel(g,cv2.CV_64F,0,1,ksize=3)
sobely=cv2.convertScaleAbs(sobely)
sobelxy=cv2.addWeighted(sobelx,0.5,sobely,0.5,0)

cv_show(&#39;sobelx&#39;,sobelx)
cv_show(&#39;sobley&#39;,sobely)
cv_show(&#39;sobelxy&#39;,sobelxy)
</code></pre>
<h2 id='3scharr算子和laplacian算子'>3.Scharr算子和laplacian算子</h2>
<p>Scharr算子和Sobel算子的区别就是它的权重矩阵差异性更大，也就是对结果的差异更加敏感.</p>
<p>Sobel算子离得近的位置是-2，+2，离得远的位置是-1，+1，而Scharr算子离得近的位置是-10,10，离得远的位置是-3,3</p>
<p>&nbsp;</p>
<p>laplacian算子对变化更加的敏感，也就是说对噪点更敏感，用于边缘检测就不太好，这个算子是与其他算子结合使用的。别的算子基本采用的是一阶导，而它是二阶导，权重矩阵中间的元素是-4，离得近的是1，离得远的是0</p>
<p>下面是三张的对比图</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240117161912896.png" referrerpolicy="no-referrer" alt="image-20240117161912896"></p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240117161924018.png" referrerpolicy="no-referrer" alt="image-20240117161924018"></p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240117161932427.png" referrerpolicy="no-referrer" alt="image-20240117161932427"></p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240117162053947.png" referrerpolicy="no-referrer" alt="image-20240117162053947"></p>
<p>这里由于颜色映射问题，SciView和cv2.imshow的结果看起来并不一样，但是能明显感觉出Sobel算子很适用于这张图的边缘检测,Scharr算子实在是太敏感了，画出的细节太多导致画面有点乱，而最后一个明显感觉噪点比第一个多一点，而且细节也不如第一个Sobe算子到位</p>
<pre><code class='language-python' lang='python'>import cv2
import matplotlib.pyplot as plt
import numpy as np
# import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/cmx.jpg&quot;)
g= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

sobelx=cv2.Sobel(g,cv2.CV_64F,1,0,ksize=3)
#要知道这样很可能算出负的值，即使会截断，它本质上也是负值，还是转化成绝对值来的比较好
sobelx=cv2.convertScaleAbs(sobelx)
sobely=cv2.Sobel(g,cv2.CV_64F,0,1,ksize=3)
sobely=cv2.convertScaleAbs(sobely)
sobelxy=cv2.addWeighted(sobelx,0.5,sobely,0.5,0)
cv_show(&quot;sobel&quot;,sobelxy)

scharrx=cv2.Scharr(g,cv2.CV_64F,1,0)
scharry=cv2.convertScaleAbs(scharrx)
scharrx=cv2.Scharr(g,cv2.CV_64F,0,1)
scharry=cv2.convertScaleAbs(scharry)
scharrxy=cv2.addWeighted(scharrx,0.5,scharry,0.5,0,dtype=cv2.CV_64F)


cv_show(&#39;scharr&#39;,scharrxy)

laplacian=cv2.Laplacian(g,cv2.CV_64F)
laplacian=cv2.convertScaleAbs(laplacian)

cv_show(&#39;laplacian&#39;,laplacian)

</code></pre>
<h1 id='十canny边缘检测'>十.Canny边缘检测</h1>
<ul>
<li>1.使用高斯滤波器，以平滑图像，滤除噪声</li>
<li>2.计算图像中每个带像素点的梯度强度和方向</li>
<li>3.应用非极大值抑制，以消除边缘检测带来的杂散响应</li>
<li>4.应用双阈值检测来确定真实和潜在的边缘</li>
<li>5.通过抑制孤立的弱边缘完成边缘检测</li>

</ul>
<h2 id='1高斯滤波'>1.高斯滤波</h2>
<p>还是采用归一化操作，用图像矩阵乘以权重矩阵。高斯滤波器的所有权值加起来等于1，越靠近中间的权重占比越大。就比如九个像素相乘这个权重矩阵之后，把这九个值加起来就是进行高斯滤波之后得到的值。对所有点重复这个过程就得到了高斯模糊过后的图像。</p>
<p>&nbsp;</p>
<h2 id='2梯度和方向'>2.梯度和方向</h2>
<p>G还是有两个算式，一个是G=sqrt(Gx²+Gy²)，一个是G=|Gx|+|Gy|</p>
<p>方向θ=arctan(Gy/Gx)</p>
<p>算梯度和方向离不开Sobel算子，Gx=Sx*A,Sx就是Sobel算子Gx方向的权重矩阵，A是图像矩阵，那么Gy也是同理的</p>
<p>&nbsp;</p>
<h2 id='3非极大值抑制'>3.非极大值抑制</h2>
<p>比如说人脸检测，画出了好几个框框， 那这个时候要选择可能性最大的那一个，把其他的几个框框给去掉，也就是抑制掉，这就是所谓的非极大值抑制。因为边界的梯度一般都比较大，所以选取梯度最大的当作图像边界了。原理就是一个像素点与周围的像素点比较梯度的幅值大小，只选择最大的保留下来。</p>
<p>主要分为两个方法</p>
<h3 id='a线性插值法'>A：线性插值法</h3>
<p>设g1的梯度赋值M（g1)，g2的梯度幅值M(g2)，则dtmp1可以这么得到：M(dtmp1)=w.M(g2)+(1-w)*M(g1)</p>
<p>其中w=distance(dtmp,1,g2)/distance(g1,g2)</p>
<p>distance(g1,g2)表示两点间的距离</p>
<h3 id='b简化法'>B：简化法</h3>
<p>为了简化计算，因为一个像素点周围有八个像素，把一个像素的梯度方向离散为八个方向，这样就只需要计算前后就行了，就不需要插值了</p>
<p>&nbsp;</p>
<h2 id='4双阈值检测'>4.双阈值检测</h2>
<p>梯度值大于&gt;maxval就处理为边界</p>
<p>minval&lt;梯度值&lt;maxval，连有边界就保留，否则舍弃</p>
<p>梯度值&lt;minval就舍弃</p>
<p><img src="file:///C:\Users\Lenovo\Documents\Tencent Files\2507560089\nt_qq\nt_data\Pic\2024-01\Ori\066f7648ed3aa1a785b38db0df73b469.png" referrerpolicy="no-referrer" alt="img"></p>
<p>双阈值检测结果如下</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240117184958820.png" referrerpolicy="no-referrer" alt="image-20240117184958820"></p>
<pre><code class='language-python' lang='python'>import cv2
import matplotlib.pyplot as plt
import numpy as np
# import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/cmx.jpg&quot;,cv2.IMREAD_GRAYSCALE)

aussian=cv2.GaussianBlur(img,(5,5),1)

v1=cv2.Canny(aussian,80,150)
v2=cv2.Canny(aussian,50,100)

res=np.hstack((v1,v2))
cv_show(&#39;res&#39;,res)
</code></pre>
<h2 id='5抑制孤立的弱边缘'>5.抑制孤立的弱边缘</h2>
<p>把上述几个结合起来，然后创建一个全为1的卷积核，并对边缘处理过后所得图像用这个卷积核进行膨胀操作，可以连接边缘，并且去除一些孤立的弱边缘</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240117190417150.png" referrerpolicy="no-referrer" alt="image-20240117190417150"></p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np

# 读取图像并转为灰度图

img = cv2.imread(&quot;C:/Users/Lenovo/Desktop/cmx.jpg&quot;, cv2.IMREAD_GRAYSCALE)

# 1. 使用高斯滤波器平滑图像，滤除噪声
gaussian = cv2.GaussianBlur(img, (5, 5), 1)

# 2. Canny 边缘检测
edges = cv2.Canny(gaussian, 80, 150)  # 使用 Canny 函数进行双阈值检测

# 3. 抑制孤立的弱边缘
kernel = np.ones((5, 5), np.uint8)
final_result = cv2.dilate(edges, kernel, iterations=1)

# 显示结果
cv2.imshow(&quot;Original Image&quot;, img)
cv2.imshow(&quot;Final Result&quot;, final_result)
cv2.waitKey(0)
cv2.destroyAllWindows()

</code></pre>
<h1 id='十一轮廓检测方法'>十一.轮廓检测方法</h1>
<h2 id='1轮廓检测结果'>1.轮廓检测结果</h2>
<p><code>cv2.findContours(img,mode,method)</code></p>
<p><strong>mode</strong>:轮廓检索模式</p>
<ul>
<li>RETR_EXTERNAL:只检索最外面的轮廓</li>
<li>RETR_LIST:检索所有的轮廓，并将其保存到一条链表中</li>
<li>RETR_CCOMP:检索所有的轮廓，并将其组织成两层:顶层是各部分的外部边界，第二层是空洞的边界</li>
<li><strong><u>RETR_TREE</u>:</strong>检索所有轮廓，并重构嵌套轮廓的整个层次</li>

</ul>
<p><strong>method</strong>:轮廓逼近方法</p>
<ul>
<li>CHAIN_APPROX_NONE:以Freeman链码的方式输出轮廓，所有其他方法输出多边形(顶点的序列)，就好像是把长方形的四条边给勾勒出来</li>
<li>CHAIN_APPROX_SIMPLE:压缩水平的、垂直的和斜的部分，也就是，函数只保留他们的终点部分，就好像是用四个点来表示一个长方形</li>

</ul>
<p>为了更高的准确率，使用二值图像</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240117194009521.png" referrerpolicy="no-referrer" alt="image-20240117194009521"></p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img = cv2.imread(&quot;C:/Users/Lenovo/Desktop/cmx.jpg&quot;, cv2.IMREAD_GRAYSCALE)

# 1. 使用高斯滤波器平滑图像，滤除噪声
gaussian = cv2.GaussianBlur(img, (5, 5), 1)

# 2. Canny 边缘检测
edges = cv2.Canny(gaussian, 80, 150)  # 使用 Canny 函数进行双阈值检测

# 3. 抑制孤立的弱边缘
kernel = np.ones((5, 5), np.uint8)
final_result = cv2.dilate(edges, kernel, iterations=1)

ret,thresh=cv2.threshold(final_result,127,255,cv2.THRESH_BINARY)

cv_show(&#39;thresh&#39;,thresh)

contours,hierarchy=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)

# 绘制轮廓
draw_img=img.copy()
&#39;&#39;&#39;
这里的参数分别是绘制图像，轮廓，轮廓索引，颜色模式，线条厚度
一定要用一个副本，不然原图会变掉的
&#39;&#39;&#39;
res=cv2.drawContours(draw_img,contours,-1,(0,0,255),2)
cv_show(&#39;res&#39;,res)
</code></pre>
<p>注意，轮廓检测我用的是边缘检测的结果，因为我直接用原图进行边缘检测效果特别差，但是注意了，一般来说轮廓的绘制还是在原灰度图上进行的。</p>
<p>&nbsp;</p>
<h2 id='2轮廓特征'>2.轮廓特征</h2>
<p>常用的轮廓特征有面积，周长等等</p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np

# 读取灰度图像
img = cv2.imread(&quot;C:/Users/Lenovo/Desktop/cmx.jpg&quot;, cv2.IMREAD_GRAYSCALE)

# 设定阈值
thresh = 128

# 大于阈值的像素值设为255，小于等于阈值的像素值设为0
retval, thresholded_img = cv2.threshold(img, thresh, 255, cv2.THRESH_BINARY)

# 查找轮廓
contours, hierarchy = cv2.findContours(thresholded_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)

# 获取第一个轮廓
contour = contours[0]

# 计算轮廓的面积
area = cv2.contourArea(contour)

# 计算轮廓的周长，True表示闭合的
perimeter = cv2.arcLength(contour, True)

# 计算轮廓的质心
M = cv2.moments(contour)
centroid_x = int(M[&quot;m10&quot;] / M[&quot;m00&quot;])
centroid_y = int(M[&quot;m01&quot;] / M[&quot;m00&quot;])

# 计算轮廓的边界框
x, y, w, h = cv2.boundingRect(contour)

# 计算轮廓的最小外接圆
(minEnclosingCircle_x, minEnclosingCircle_y), minEnclosingCircle_radius = cv2.minEnclosingCircle(contour)

# 计算轮廓的椭圆拟合
ellipse = cv2.fitEllipse(contour)

# 在图像上绘制轮廓和特征
cv2.drawContours(img, [contour], -1, (0, 255, 0), 2)
cv2.circle(img, (centroid_x, centroid_y), 5, (0, 0, 255), -1)
cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)
cv2.circle(img, (int(minEnclosingCircle_x), int(minEnclosingCircle_y)), int(minEnclosingCircle_radius), (255, 255, 0), 2)
cv2.ellipse(img, ellipse, (0, 255, 255), 2)

# 显示结果
cv2.imshow(&quot;Original Image&quot;, img)
cv2.waitKey(0)
cv2.destroyAllWindows()

</code></pre>
<p>&nbsp;</p>
<h2 id='3轮廓近似'>3.轮廓近似</h2>
<p>轮廓近似其实就是把曲线给近似成直线</p>
<p>比如A到B是一条曲线，那就先用虚线连接A到B，然后再在这个曲线上面找一点C，使得C到直线AB的距离最大，这个点应该就是所谓的拉格朗日点。这条最长线段记作d,如果d小于阈值，就符合要求了。如果d大于阈值，那么这个曲线就不能用一条直线来近似了。这个时候，就要连接AC和BC，然后看AC的曲线能否用AC的直线代替，BC的曲线能否用BC的直线代替。然后看看AC的曲线和BC的曲线是否满足小于阈值的条件，如果不满足，那就一直二分，直到满足都小于阈值的条件就行了。</p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/lena.png&quot;)
gray=cv2.cvtColor(img,cv2.COLOR_BGRA2GRAY)
ret,thresh=cv2.threshold(gray,127,255,cv2.THRESH_BINARY)
contours,hierarchy=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)
cnt=contours[0]

draw_img=img.copy()
res=cv2.drawContours(draw_img,[cnt],-1,(0,0,255),2)
cv_show(&#39;res&#39;,res)

#epsilon指定的越小，就和原来的轮廓越相近
epsilon=0.1*cv2.arcLength(cnt,True)
approx=cv2.approxPolyDP(cnt,epsilon,True)
draw_img=img.copy()
res=cv2.drawContours(draw_img,[approx],-1,(0,0,255),2)
cv_show(&#39;res&#39;,res)
</code></pre>
<p>下面是一些识别常见形状的方法</p>
<h3 id='1边界矩形'>1.边界矩形</h3>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/lena.png&quot;)
gray=cv2.cvtColor(img,cv2.COLOR_BGRA2GRAY)
ret,thresh=cv2.threshold(gray,127,255,cv2.THRESH_BINARY)
contours,hierarchy=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)
cnt=contours[0]

x,y,w,h=cv2.boundingRect(cnt)
img=cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)
cv_show(&quot;img&quot;,img);

area=cv2.contourArea(cnt)
rect_area=w*h
extent=float(area)/rect_area
print(&quot;轮廓面积与边界矩形比&quot;,extent)
</code></pre>
<h3 id='2外接圆'>2.外接圆</h3>
<pre><code class='language-python' lang='python'># 外接圆
(x,y),radius=cv2.minEnclosingCircle(cnt)
center=(int(x),int(y))
radius=int(radius)
img=cv2.circle(img,center,radius,(0,255,0),2)
cv_show(img,&#39;img&#39;)
</code></pre>
<p>&nbsp;</p>
<h1 id='十二模板匹配方法'>十二.模板匹配方法</h1>
<p>模板匹配和卷积原理很像，模板在原图像上从原点开始滑动，计算模板与图像被模板覆盖的地方的差别程度，这个差别程度的计算方法OpenCV提供了六种，每次将计算的结果放在一个矩阵里面作为结果输出。如果原图是A×B大小，模板是A×B大小，那么输出结果的矩阵就是(A-a+1)×(B-b+1)</p>
<ul>
<li>TM_SQDIFF:计算平方不同，计算出来的值越小越相关</li>
<li>TM_CCORR：计算相关性，计算出来的值越大越相关</li>
<li>TM_CCOEFF：计算相关系数，计算出来的值越大越相关</li>
<li>TM_SQDIFF_NORMED:计算归一化平方不同，计算出来的值越接近0越相关</li>
<li>TM_CCORR_NORMED：计算归一化相关性，计算出来的值越接近1越相关</li>
<li>TM_CCOEFF_NORMED:计算归一化相关系数，计算出来的值越接近1越相关</li>

</ul>
<p>OPENCV的minMaxLoc函数返回的最值位置很有用，比如说用SQDIFF模式匹配的时候，计算出来的最小值位置min_loc就是模板匹配到的矩阵左上角的元素位置，通过模板匹配结果的h和w就可以将整个模板匹配矩阵给画出来</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240118205944226.png" referrerpolicy="no-referrer" alt="image-20240118205944226"></p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np
import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/lena.png&quot;,0)
template=cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/face.png&quot;,0)
h,w=template.shape[:2]
res=cv2.matchTemplate(img,template,cv2.TM_SQDIFF)


methods=[&#39;cv2.TM_CCOEFF&#39;,&#39;cv2.TM_CCOEFF_NORMED&#39;,&#39;cv2.TM_CCORR&#39;,&#39;cv2.TM_CCORR_NORMED&#39;,&#39;cv2.TM_SQDIFF&#39;,&#39;cv2.TM_SQDIFF_NORMED&#39;]
for meth in methods:
    img2=img.copy()

    #匹配方法的真值
    method=eval(meth)
    print(meth,method)
    #res返回的是每一个窗口得到的结果值
    res=cv2.matchTemplate(img,template,method)
    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)

    #如果是平方差匹配，那么越接近0越能匹配，就选择最小值
    if method in [cv2.TM_SQDIFF,cv2.TM_SQDIFF_NORMED]:
        top_left=min_loc
    else :
        top_left=max_loc
    bottom_right=(top_left[0]+w,top_left[1]+h)

    #绘制矩形
    cv2.rectangle(img2,top_left,bottom_right,255,2)

    plt.subplot(121),plt.imshow(res,cmap=&#39;gray&#39;)
    #隐藏坐标轴
    plt.xticks([]),plt.yticks([])
    plt.subplot(122),plt.imshow(img2,cmap=&#39;gray&#39;)
    plt.xticks([]), plt.yticks([])
    plt.suptitle(meth)
    plt.show()

</code></pre>
<p>总的来说呢，还是用带归一化的效果要更胜一筹，平时使用也可以优先考虑归一化的</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240118210142588.png" referrerpolicy="no-referrer" alt="image-20240118210142588"></p>
<p>&nbsp;</p>
<h2 id='匹配多个对象'>匹配多个对象</h2>
<p>有的时候我们需要用一个模板去匹配多个对象，以下就是实现方法</p>
<pre><code class='language-python' lang='python'>img_rgb=cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/lena.png&quot;)
img_gray=cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/lena.png&quot;,cv2.COLOR_BGR2GRAY)
template=cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/face.png&quot;,0)
h,w=template.shape[:2]

res=cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)

thereshold=0.8
#取匹配程度大于百分之八十的坐标
loc=np.where(res&gt;=threshold)

#*表示可选参数
for pt in zip(*loc[::-1]):
	bottom_right=(pt[0]+w,pt[1]+h)
	cv2.rectangle(img_rgb,bottom_right,(0,0,255),2)
	
cv_show(&#39;img_rgb&#39;,img_rgb)
</code></pre>
<h2 id='用图像金字塔优化模板匹配'>用图像金字塔优化模板匹配</h2>
<p>一般可以用图像金字塔来减少匹配时间，提高效率，一个本来秒级别的模板匹配速度可以通过图像金字塔优化到毫秒级别，常见的图像金字塔有高斯金字塔（向下采样方法，也就是缩小）和拉普拉斯金字塔（向上采样方法，也就是放大）</p>
<p>可以对模板和图像分别做图像金字塔，从金字塔尖开始匹配，由于分辨率较小，匹配时间较短，接着在此位置基础上，在下一层该位置周围局部区域继续进行匹配，直到最后一层完成匹配，整体思路为course-to-fine</p>
<h1 id='十三霍夫变换'>十三.霍夫变换</h1>
<p>霍夫变换经常用于提取图像里面的直线和园等几何形状</p>
<p>比如一个图像中，出现了多条线和圆，霍夫线变换就会保留图像中的几条直线，霍夫圆变化就提取出图像中的几个圆</p>
<h2 id='1原理'>1.原理</h2>
<p>一条直线是由两个端点确定的，可以写成y=kx+q</p>
<p>那么就有 </p>
<div contenteditable="true" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n333" cid="n333" mdtype="math_block" data-math-tag-before="0" data-math-tag-after="0" data-math-labels="[]"><div class="md-rawblock-container md-math-container" tabindex="-1"><mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="14.428ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 6377 899" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.464ex;" class="in-text-selection"><defs><path id="MJX-5-TEX-I-1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path><path id="MJX-5-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-5-TEX-N-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path id="MJX-5-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path id="MJX-5-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-5-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-5-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-5-TEX-I-1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D45E" xlink:href="#MJX-5-TEX-I-1D45E"></use></g><g data-mml-node="mo" transform="translate(737.8,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="mo" transform="translate(1793.6,0)"><use data-c="2212" xlink:href="#MJX-5-TEX-N-2212"></use></g><g data-mml-node="mi" transform="translate(2571.6,0)"><use data-c="1D458" xlink:href="#MJX-5-TEX-I-1D458"></use></g><g data-mml-node="mi" transform="translate(3092.6,0)"><use data-c="1D465" xlink:href="#MJX-5-TEX-I-1D465"></use></g><g data-mml-node="mn" transform="translate(3664.6,0)"><use data-c="31" xlink:href="#MJX-5-TEX-N-31"></use></g><g data-mml-node="mo" transform="translate(4386.8,0)"><use data-c="2B" xlink:href="#MJX-5-TEX-N-2B"></use></g><g data-mml-node="mi" transform="translate(5387,0)"><use data-c="1D466" xlink:href="#MJX-5-TEX-I-1D466"></use></g><g data-mml-node="mn" transform="translate(5877,0)"><use data-c="31" xlink:href="#MJX-5-TEX-N-31"></use></g></g></g></svg></mjx-container></div></div>
<div contenteditable="true" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n334" cid="n334" mdtype="math_block" data-math-tag-before="0" data-math-tag-after="0" data-math-labels="[]"><div class="md-rawblock-container md-math-container" tabindex="-1"><mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="14.428ex" height="2.034ex" role="img" focusable="false" viewBox="0 -694 6377 899" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.464ex;" class="in-text-selection"><defs><path id="MJX-6-TEX-I-1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path><path id="MJX-6-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-6-TEX-N-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path id="MJX-6-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path id="MJX-6-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-6-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-6-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-6-TEX-I-1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D45E" xlink:href="#MJX-6-TEX-I-1D45E"></use></g><g data-mml-node="mo" transform="translate(737.8,0)"><use data-c="3D" xlink:href="#MJX-6-TEX-N-3D"></use></g><g data-mml-node="mo" transform="translate(1793.6,0)"><use data-c="2212" xlink:href="#MJX-6-TEX-N-2212"></use></g><g data-mml-node="mi" transform="translate(2571.6,0)"><use data-c="1D458" xlink:href="#MJX-6-TEX-I-1D458"></use></g><g data-mml-node="mi" transform="translate(3092.6,0)"><use data-c="1D465" xlink:href="#MJX-6-TEX-I-1D465"></use></g><g data-mml-node="mn" transform="translate(3664.6,0)"><use data-c="32" xlink:href="#MJX-6-TEX-N-32"></use></g><g data-mml-node="mo" transform="translate(4386.8,0)"><use data-c="2B" xlink:href="#MJX-6-TEX-N-2B"></use></g><g data-mml-node="mi" transform="translate(5387,0)"><use data-c="1D466" xlink:href="#MJX-6-TEX-I-1D466"></use></g><g data-mml-node="mn" transform="translate(5877,0)"><use data-c="32" xlink:href="#MJX-6-TEX-N-32"></use></g></g></g></svg></mjx-container></div></div>
<p>那么这个时候，原本的图像就可以表示为，以k为横坐标，q为纵坐标的坐标系了，这种变换后的空间被称为霍夫空间。即：笛卡尔坐标系中的一条直线，对应霍夫空间中的一个点。反过来也同样成立，霍夫空间中的一条线，也对应笛卡尔坐标系中的一个点。</p>
<p>&nbsp;</p>
<p>那么如果有A，B，两个点，对应到霍夫空间中就是两条直线，这两条直线会有一个交点。那这个交点，也就是由AB两点决定的直线的斜率和截距</p>
<p>&nbsp;</p>
<p>如果在笛卡尔坐标系的多个点共线，那么这些点同样在霍夫空间中对应的直线会交于一点</p>
<p>&nbsp;</p>
<p>当如果不止存在一条直线的时候，我们就要选择尽可能多的直线交汇成的点</p>
<p>&nbsp;</p>
<p>当存在笛卡尔坐标系中多个点共线的时候，有的时候不好确定其p和q，比如这三个点的x或者y坐标相等，这个时候就要转化为极坐标(p，θ)，p就是原点到直线的垂直距离，θ就是直线的垂线与横轴顺时针方向的夹角。垂直线的角度是0度，水平线的角度是180度，我们只需要求出霍夫空间中交点的位置，就一定能获得原坐标下的直线</p>
<p>&nbsp;</p>
<h2 id='2实现流程'>2.实现流程</h2>
<p>假设有一个100*100的图片，使用霍夫变换检测直线的步骤如下：</p>
<ul>
<li><p>直线都用(p,θ)表示，先创建一个二维数组，就叫其累加器，初始化所有的值为0，行就是p,列表示θ。(数组的大小决定了精确性，如果希望角度精确在1度，那就要180列。p的最大值是图片对角线的距离，如果希望精度达到像素级别，行数应该和图像对角线的距离相等)</p>
</li>
<li><p>取出直线上的第一个点(x,y)，将其代入直线在极坐标的公式中，然后从0遍历到180，分别求出对应P值，如果这个数值在对应的累加器上面存在相应的位置，那就在该位置上+1</p>
</li>
<li><p>取出直线上的第二个点重复步骤，不断更新累加器的值，对图像中的直线的每个点都执行上述步骤哦，每次更新累加器中的值</p>
</li>
<li><p>搜索累加器中的最大值，找到对应的(p,θ)，也就是横纵坐标，就可以将图像中的直线表达出来了</p>
<p>整个流程总结一下：就是在累加器上画霍夫线然后找到最大点</p>
</li>

</ul>
<p>&nbsp;</p>
<h2 id='3代码实现'>3.代码实现</h2>
<p>在OpenCV中做霍夫检测的API是</p>
<p><code>cv.HoughLines(img,rho,theta,threshold)</code></p>
<ul>
<li>这里面的Img必须先二值化处理，或者进行canny边缘检测</li>
<li>rho,theta 是p和θ的精确度</li>
<li>thereshold是阈值，只有累加器中的值高于这个阈值的时候才会被认定是直线</li>

</ul>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np
import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

def get_ROI(img,h1,h2,w1,w2):
    if h2&gt;img.shape[0] or w2&gt;img.shape[1]:
        print(&quot;out of range&quot;)
    roi=img[h1:h2,w1:w2]
    return roi


#img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/playground.png&quot;)
img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/strightPlayground.png&quot;)
#roi=get_ROI(img,350,573,0,800)
roi=get_ROI(img,30,img.shape[0],0,img.shape[1])
gray=cv2.cvtColor(roi,cv2.COLOR_BGRA2GRAY)
edges=cv2.Canny(gray,100,150)
cv_show(&#39;edges&#39;,edges)

# 霍夫直线变化
lines=cv2.HoughLines(edges,0.8,np.pi/180,180)

# 绘图
for line in lines:
    rho,theta=line[0]
    a=np.cos(theta)
    b=np.sin(theta)
    x0=a*rho
    y0=b*rho
    x1=int(x0+1000*(-b))
    y1=int(y0+1000*(a))
    x2=int(x0-1000*(-b))
    y2=int(y0-1000*(a))
    cv2.line(roi,(x1,y1),(x2,y2),(0,255,0))

#图像显示
plt.figure(figsize=(10,8))
plt.imshow(img[:,:,::-1]),plt.title(&#39;HuffLines&#39;)
plt.xticks([]),plt.yticks([])
plt.show()
</code></pre>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240119010958917.png" referrerpolicy="no-referrer" alt="image-20240119010958917"><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240119010940839.png" referrerpolicy="no-referrer" alt="image-20240119010940839"></p>
<h2 id='4霍夫圆检测'>4.霍夫圆检测</h2>
<p>既然霍夫变换可以用来检测直线，那么也可以用来检测更多的形状，比如圆形。</p>
<p>圆的表达式是</p>
<div contenteditable="true" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n373" cid="n373" mdtype="math_block" data-math-tag-before="0" data-math-tag-after="0" data-math-labels="[]"><div class="md-rawblock-container md-math-container" tabindex="-1"><mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="22.479ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 9935.6 1000" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.566ex;" class="in-text-selection"><defs><path id="MJX-7-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-7-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-7-TEX-N-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path id="MJX-7-TEX-I-1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path id="MJX-7-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJX-7-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-7-TEX-I-1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-7-TEX-I-1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path><path id="MJX-7-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-7-TEX-I-1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="28" xlink:href="#MJX-7-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(389,0)"><use data-c="1D465" xlink:href="#MJX-7-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(1183.2,0)"><use data-c="2212" xlink:href="#MJX-7-TEX-N-2212"></use></g><g data-mml-node="mi" transform="translate(2183.4,0)"><use data-c="1D44E" xlink:href="#MJX-7-TEX-I-1D44E"></use></g><g data-mml-node="mo" transform="translate(2712.4,0)"><use data-c="29" xlink:href="#MJX-7-TEX-N-29"></use></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(3101.4,0)"><g data-mml-node="mo"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">²</text></g></g><g data-mml-node="mo" transform="translate(3777.5,0)"><use data-c="2B" xlink:href="#MJX-7-TEX-N-2B"></use></g><g data-mml-node="mo" transform="translate(4777.7,0)"><use data-c="28" xlink:href="#MJX-7-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(5166.7,0)"><use data-c="1D466" xlink:href="#MJX-7-TEX-I-1D466"></use></g><g data-mml-node="mo" transform="translate(5879,0)"><use data-c="2212" xlink:href="#MJX-7-TEX-N-2212"></use></g><g data-mml-node="mi" transform="translate(6879.2,0)"><use data-c="1D44F" xlink:href="#MJX-7-TEX-I-1D44F"></use></g><g data-mml-node="mo" transform="translate(7308.2,0)"><use data-c="29" xlink:href="#MJX-7-TEX-N-29"></use></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(7697.2,0)"><g data-mml-node="mo"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">²</text></g></g><g data-mml-node="mo" transform="translate(8428.8,0)"><use data-c="3D" xlink:href="#MJX-7-TEX-N-3D"></use></g><g data-mml-node="mi" transform="translate(9484.6,0)"><use data-c="1D45F" xlink:href="#MJX-7-TEX-I-1D45F"></use></g></g></g></svg></mjx-container></div></div>
<p>在opencv中采用霍夫梯度法进行圆形的检测</p>
<p>霍夫梯度法将霍夫圆检测分为两个阶段</p>
<p>第一个阶段检测圆心，第二个阶段利用圆心推导圆的半径</p>
<ul>
<li>圆心检测的原理：圆心是圆周法线的交汇处，设置一个阈值，在某点的相交的直线条数大于这个阈值就认为该交汇点为圆心</li>
<li>圆半径确定原理：圆心到圆周上的距离(半径)是相同的，确定一个阈值，只要相同距离的数量大于该阈值，就认为该距离是圆心的半径</li>

</ul>
<p>原则上霍夫变换是可以检测任何形状的，但是复杂形状需要的参数就越多，霍夫空间的维度也越多，在程序实现上不利于把标准霍夫变换应用到复杂图形的检测中。霍夫梯度法是霍夫变换的改进，目的是减小霍夫空间的维度，提高效率</p>
<p><code>circles=cv.HoughCircles(image,method,dp,minDist,param1=100,param2=100,minRadius=0,maxRadius=0)</code></p>
<ul>
<li>image，要传入一个灰度图</li>
<li>method,使用霍夫变换圆检测的算法，参数是CV2.HOUGH_GRADIENT</li>
<li>dp:霍夫空间的分辨率，1的时候和输入空间大小一致，2的时候是输入图像空间的一半</li>
<li>minDist:圆心之间的最小距离，如果检测到的两个圆心小于这个阈值就认为他们是同一个圆心</li>
<li>param1:边缘检测时使用Canny算子的高阈值，低阈值是高阈值的一半</li>
<li>param2:检测圆心和确定半径时所共有的阈值</li>
<li>minRadius和maxRadius为检测到的圆的半径的最小值和最大值</li>

</ul>
<p>最终这个API返回一个cicrles,它就是输出圆向量，包含三个浮点型的元素，圆心的横坐标，纵坐标和圆的半径</p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np
import matplotlib.pyplot as plt

gray=cv2.imread(&quot;C://Users//Lenovo//Desktop//pictures//round.png&quot;,0)

# 进行一个中值滤波
img=cv2.medianBlur(gray,7)

# 霍夫圆检测
circles=cv2.HoughCircles(img,cv2.HOUGH_GRADIENT,1,200,param1=100,param2=30,minRadius=0,maxRadius=100)

# 绘图
for in in circles[0,:]:# 遍历每一行的数据
	cv2.circle(gray,(i[0],i[1]),(0,0,255),2)
	cv2.circle(gray,(i[0],i[1]),(0,0,255),3)

plt.figure(figsize=(10,8),dpi=100)
plt.inshow(gray[:,:,::-1]),plt.title(&quot;HoughRound&quot;)
plt.xticks([]),plt.yticks([])
plt.show()
</code></pre>
<p>&nbsp;</p>
<h1 id='十四直方图'>十四.直方图</h1>
<p>横坐标用0-255,表示，纵坐标为对应的值出现的次数，这就是直方图。它反应了像素点的值的分布。</p>
<p><code>cv2.calcHist(images,channels,mask,histSize,ranges)</code></p>
<ul>
<li>image的原图像格式是uint8或者是float32，当传入函数的时候应该用中括号来表示，如[img]</li>
<li>channels也要用中括号括起来，它会告诉我们统幅图像的直方图。如果图像是灰度那就是[0]，如果传入的是彩色图像那就可以是[0],[1],[2]，他们分别对应BGR</li>
<li>mask:掩膜图像。统整幅图像的直方图就把它设置为None，，如果喜爱那个统图像某一分的直方图就制作一个掩膜图像并且使用它</li>
<li>histSize就是BIN的数目，也需要用中括号扩起来。比如可以不设置成0-255每个位置一一对应，纵坐标可以0-10.20-30这样的</li>
<li>ranges表示像素值的范围，通常是[0,256]</li>

</ul>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240119133658594.png" referrerpolicy="no-referrer" alt="image-20240119133658594"></p>
<pre><code class='language-python' lang='python'>import cv2
import matplotlib.pyplot as plt

img=cv2.imread(&quot;C://Users//Lenovo//Desktop//pictures//lena.png&quot;,cv2.IMREAD_GRAYSCALE)
hist=cv2.calcHist([img],[0],None,[256],[0,256])
print(hist.shape)

plt.hist(img.ravel(),256)
plt.show()
</code></pre>
<p>当然也可以读取彩色的</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240119134152647.png" referrerpolicy="no-referrer" alt="image-20240119134152647"></p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np
import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

def get_ROI(img,h1,h2,w1,w2):
    if h2&gt;img.shape[0] or w2&gt;img.shape[1]:
        print(&quot;out of range&quot;)
    roi=img[h1:h2,w1:w2]
    return roi

img=cv2.imread(&quot;C://Users//Lenovo//Desktop//pictures//lena.png&quot;)
color=[&#39;b&#39;,&#39;g&#39;,&#39;r&#39;]
for i,col in enumerate(color):
    histr=cv2.calcHist([img],[i],None,[256],[0,256])
    plt.plot(histr,color=col)
    plt.xlim([0,256])


plt.show()
</code></pre>
<p>&nbsp;</p>
<h2 id='1掩膜mask的操作'>1.掩膜mask的操作</h2>
<p>掩膜的官方定义是一个由0和1组成的二进制图像，利用该掩膜图像对要处理的图像进行掩膜，其中1值的区域被处理，0值的区域会被屏蔽，不会处理。我个人的理解就是AE,PR中的蒙版。</p>
<p>掩膜的主要用途：</p>
<ul>
<li>提取感兴趣区域，用预先制作的掩膜与待处理图像进行与操作，得到感兴趣区域图像，感兴趣区域内图像值保持不变，而区外图像值都为0</li>
<li>屏蔽作用：用掩膜对图像上某些区域做屏蔽，使其不参与处理或者不参加处理图像的计算，或者仅对屏蔽区域做处理或者统计</li>
<li>结构特征提取：用相似性变量或者图像匹配方法检测和提取掩膜相似的结构特征</li>
<li>掩膜mask在直方图的主要作用是用于查找特定区域的直方图，在需要查找的位置上创建一个白色的掩膜图像，否则创建成黑色的，然后将其作为掩码mask传递就行了</li>

</ul>
<pre><code class='language-python' lang='python'># 创建mask
mask=np.zeros(img.shape[:2],np.uint8)
mask[100:300,100:400]=255
cv_show(&#39;mask&#39;,mask)
</code></pre>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240121152956333.png" referrerpolicy="no-referrer" alt="image-20240121152956333"></p>
<p>有了掩膜，我们就可以把图片也给放进来了，执行一个与操作就行了</p>
<pre><code class='language-python' lang='python'>img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/playground.png&quot;)

# 创建mask
mask=np.zeros(img.shape[:2],np.uint8)
mask[100:300,100:400]=255
cv_show(&#39;mask&#39;,mask)

masked_img=cv2.bitwise_and(img,img,mask=mask)
cv_show(&#39;masked_img&#39;,masked_img)
</code></pre>
<p>&nbsp;</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240121153340611.png" referrerpolicy="no-referrer" alt="image-20240121153340611"></p>
<h2 id='2直方图的均衡化'>2.直方图的均衡化</h2>
<p>一般来说，有的直方图的分布是不够均衡的，比如说集中出现在某一个像素点上面。我们可以通过让其分布均衡一些，以达到增强图像对比度的效果。均衡化采用的是用一个函数计算，使得一种分布映射到另外一种分布。通过计算灰度值的概率，算他们的累加概率，然后用累加概率根据函数映射之后生成的新灰度值进行一个取整操作，就实现了直方图的均衡化。</p>
<p>这个公式可以表达为</p>
<div contenteditable="true" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n443" cid="n443" mdtype="math_block" data-math-tag-before="0" data-math-tag-after="0" data-math-labels="[]"><div class="md-rawblock-container md-math-container" tabindex="-1"><mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="32.05ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 14165.9 1000" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.566ex;" class="in-text-selection"><defs><path id="MJX-8-TEX-I-1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path><path id="MJX-8-TEX-I-1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path id="MJX-8-TEX-I-1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path id="MJX-8-TEX-I-1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-8-TEX-I-1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path id="MJX-8-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-8-TEX-I-1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path><path id="MJX-8-TEX-N-2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path><path id="MJX-8-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-8-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D463" xlink:href="#MJX-8-TEX-I-1D463"></use></g><g data-mml-node="mi" transform="translate(485,0)"><use data-c="1D44E" xlink:href="#MJX-8-TEX-I-1D44E"></use></g><g data-mml-node="mi" transform="translate(1014,0)"><use data-c="1D459" xlink:href="#MJX-8-TEX-I-1D459"></use></g><g data-mml-node="mi" transform="translate(1312,0)"><use data-c="1D462" xlink:href="#MJX-8-TEX-I-1D462"></use></g><g data-mml-node="mi" transform="translate(1884,0)"><use data-c="1D452" xlink:href="#MJX-8-TEX-I-1D452"></use></g><g data-mml-node="mo" transform="translate(2627.8,0)"><use data-c="3D" xlink:href="#MJX-8-TEX-N-3D"></use></g><g data-mml-node="mi" transform="translate(3683.6,0)"><use data-c="1D45D" xlink:href="#MJX-8-TEX-I-1D45D"></use></g><g data-mml-node="mtext" transform="translate(4186.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">累</text></g><g data-mml-node="mtext" transform="translate(5011.7,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">计</text></g><g data-mml-node="mo" transform="translate(6059.8,0)"><use data-c="2217" xlink:href="#MJX-8-TEX-N-2217"></use></g><g data-mml-node="mo" transform="translate(6782,0)"><use data-c="28" xlink:href="#MJX-8-TEX-N-28"></use></g><g data-mml-node="mtext" transform="translate(7171,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">灰</text></g><g data-mml-node="mtext" transform="translate(7997,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">度</text></g><g data-mml-node="mtext" transform="translate(8822.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">值</text></g><g data-mml-node="mtext" transform="translate(9648.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">的</text></g><g data-mml-node="mtext" transform="translate(10474,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">取</text></g><g data-mml-node="mtext" transform="translate(11299.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">值</text></g><g data-mml-node="mtext" transform="translate(12125.8,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">范</text></g><g data-mml-node="mtext" transform="translate(12951.8,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">围</text></g><g data-mml-node="mo" transform="translate(13776.9,0)"><use data-c="29" xlink:href="#MJX-8-TEX-N-29"></use></g></g></g></svg></mjx-container></div></div>
<p>比如灰度值50的点，它的累计概率是0.25，灰度值取值范围是0-255，</p>
<p>那么经过映射取整之后就是64</p>
<h2 id='3均衡化的代码实现'>3.均衡化的代码实现</h2>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240121160927197.png" referrerpolicy="no-referrer" alt="image-20240121160927197"></p>
<p>这是均衡化之前的效果，可以看到分布差异非常非常巨大</p>
<p>下图是均衡化之后的效果</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240121160938730.png" referrerpolicy="no-referrer" alt="image-20240121160938730"></p>
<p>可以发现对比起来真的好了很多很多</p>
<p>&nbsp;</p>
<p>他们在图像上对应是这样的</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240121161048739.png" referrerpolicy="no-referrer" alt="image-20240121161048739"></p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240121161025243.png" referrerpolicy="no-referrer" alt="image-20240121161025243"></p>
<p>可以看到，图像对比度确确实实的增强了很多很多很多</p>
<pre><code class='language-python' lang='python'>img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/playground.png&quot;,0)

equ=cv2.equalizeHist(img)
plt.hist(equ.ravel(),256)
plt.show()
cv_show(&#39;img&#39;,img)
cv_show(&#39;equ&#39;,equ)
</code></pre>
<p>&nbsp;</p>
<h2 id='4自适应直方图均衡化'>4.自适应直方图均衡化</h2>
<p>要知道均衡化有的时候会造成细节上的丢失，所以要对直方图进行自适应的均衡化，在拉高对比度的同时减少细节的丢失</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240121163247185.png" referrerpolicy="no-referrer" alt="image-20240121163247185"></p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240121163306463.png" referrerpolicy="no-referrer" alt="image-20240121163306463"></p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240121163231133.png" referrerpolicy="no-referrer" alt="image-20240121163231133"></p>
<p>可以看出，第三张在对比度和细节之间实现了均衡</p>
<pre><code class='language-python' lang='python'>img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/playground.png&quot;,0)

equ=cv2.equalizeHist(img)
clahe=cv2.createCLAHE(clipLimit=2.0,tileGridSize=(8,8))
res_clahe=clahe.apply(img)

cv_show(&#39;img&#39;,img)
cv_show(&#39;equ&#39;,equ)
cv_show(&#39;res_clahe&#39;,res_clahe)
</code></pre>
<p>自适应直方图其实就是把一个图像分为很多很多小块，然后各自做每个区域的均衡化。 </p>
<p>这里的参数clipLimit其实就是对比度限制，对比度超过这个值的像素会被截断，以防对比度被过度增强</p>
<p>这里的titleGridSize是被分割的图像的小块的大小，默认就是(8,8)</p>
<p>&nbsp;</p>
<h1 id='十五傅里叶变换'>十五.傅里叶变换</h1>
<p>傅里叶不以时间做参照分析，而是更关心事物发生的频率，在频率中，一切都是静止的。</p>
<p>任何的周期函数，都可以用正弦波堆叠出来！</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240121165052888.png" referrerpolicy="no-referrer" alt="image-20240121165052888"></p>
<h2 id='1傅里叶变换的作用'>1.傅里叶变换的作用</h2>
<ul>
<li>高频：变化剧烈的灰度分量，比如边界</li>
<li>低频：变化缓慢的灰度分量，比如一片大海</li>

</ul>
<h2 id='2滤波'>2.滤波</h2>
<ul>
<li>低通滤波器：只保留低频，会使得图像模糊</li>
<li>高通滤波器：只保留高频，会使得图像细节增强</li>

</ul>
<h2 id='3api'>3.API</h2>
<ul>
<li>OPENCV中提供了cv2.dft()和cv2.cv2.idft()，输入图像必须先转换为np.float32格式</li>
<li>得到的结果中频率为0的部分会在左上角，通常要转换到中心位置，可以通过shift变换实现</li>
<li>cv2.dft()返回的结果是双通道的(实部，虚部)，通常要转换为图像格式才能实现(0,255)</li>
<li>fftshift()和ifftshift()互为逆运算，一个是把左上角放到中间，一个是从中间换回左上角</li>

</ul>
<p>&nbsp;</p>
<h2 id='4频域变换'>4.频域变换</h2>
<pre><code class='language-python' lang='python'>img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/playground.png&quot;,0)

#opencv官方的要求格式
img_float32=np.float32(img)
dft=cv2.dft(img_float32,flags=cv2.DFT_COMPLEX_OUTPUT)

#将低频值转换到中间的位置
dft_shift=np.fft.fftshift(dft)

#得到灰度图能表示的形式
magnitude_spectrum=20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))

plt.subplot(121),plt.imshow(img,cmap=&#39;gray&#39;)
plt.title(&quot;Input image&quot;),plt.xticks([]),plt.yticks([])
plt.subplot(122),plt.imshow(magnitude_spectrum,cmap=&#39;gray&#39;)
plt.title(&#39;Magnitude Spectrum&#39;),plt.xticks([]),plt.yticks([])
plt.show()
</code></pre>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240121172746972.png" referrerpolicy="no-referrer" alt="image-20240121172746972"></p>
<h2 id='5低频滤波和高频滤波'>5.低频滤波和高频滤波</h2>
<p>把区域的中心位置设置为1，其他设置设置为0，也就是说在图像中间构造一个掩膜，把频率低的保留在中间这个掩膜位置，这就是低通滤波。</p>
<pre><code class='language-python' lang='python'>img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/playground.png&quot;,0)

img_float32=np.float32(img)

dft=cv2.dft(img_float32,flags=cv2.DFT_COMPLEX_OUTPUT)

dft_shift=np.fft.fftshift(dft)

rows,cols=img.shape

crow,ccol=int(rows/2),int(cols/2) #中心位置

#低通滤波
mask=np.zeros((rows,cols,2),np.uint8)
mask[crow-30:crow+30,ccol-30:ccol+30]=1

#IDFT
fshift=dft_shift*mask
f_ishift=np.fft.ifftshift(fshift)
img_back=cv2.idft(f_ishift)
#还需要对实部和虚部进行处理才能展示
img_back=cv2.magnitude(img_back[:,:,0],img_back[:,:,:1])
</code></pre>
<p>可以看到低频滤波只保留了低频部分，使得图像模糊了</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240121192714835.png" referrerpolicy="no-referrer" alt="image-20240121192714835"></p>
<p>高频滤波和低频滤波是恰恰相反。我们知道经过变化之后低频被放到了图像中间区域，那么低频滤波是只要中间的一块低频掩膜部分，而高频滤波就是舍弃掉中间的低频掩膜部分，而保留外部的四个边角部分。</p>
<p>高频滤波的图像处理结果是这样的，可以看到几乎只保留了边界的信息。</p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240124130854660.png" referrerpolicy="no-referrer" alt="image-20240124130854660"></p>
<pre><code class='language-python' lang='python'>import cv2
import numpy as np
import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow(name,img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(img.shape)

def get_ROI(img,h1,h2,w1,w2):
    if h2&gt;img.shape[0] or w2&gt;img.shape[1]:
        print(&quot;out of range&quot;)
    roi=img[h1:h2,w1:w2]
    return roi


img=cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/playground.png&quot;,0)

img_float32=np.float32(img)

dft=cv2.dft(img_float32,flags=cv2.DFT_COMPLEX_OUTPUT)

dft_shift=np.fft.fftshift(dft)

rows,cols=img.shape

crow,ccol=int(rows/2),int(cols/2) #中心位置

#高通滤波
mask=np.ones((rows,cols,2),np.uint8)
mask[crow-30:crow+30,ccol-30:ccol+30]=0

#IDFT
fshift=dft_shift*mask
f_ishift=np.fft.ifftshift(fshift)
img_back=cv2.idft(f_ishift)
img_back=cv2.magnitude(img_back[:,:,0],img_back[:,:,:1])

plt.subplot(121),plt.imshow(img,cmap=&#39;gray&#39;)
plt.subplot(122),plt.imshow(img_back,cmap=&#39;gray&#39;)
plt.show()
</code></pre>
<p>&nbsp;</p>
<h1 id='十六harris角点检测'>十六.harris角点检测</h1>
<p>&nbsp;</p>
<h2 id='1数学原理'>1.数学原理</h2>
<p>图像中可以分为三个区域：平面，边界，角点</p>
<ul>
<li>平面：沿着图像X轴和Y轴变化都十分缓慢的，也就是两个特征值都小，且近似相等，自相关函数数值在各个方向上都小</li>
<li>边界：沿着某一个坐标轴变化十分迅速的，一个特征值大，一个特征值小，自相关函数数值在某一方向上大，在其他方向上小</li>
<li>角点：沿着图像X轴和Y轴变化都十分迅速的，两个特征值都大，且近似相等，自相关函数在所有方向上都增大</li>

</ul>
<p>变化，指的是灰度值的变换，比如对于图像I(x,y)，我们可以对其进行平移操作来观察平移前后，它的自相似性。整个数学计算公式非常复杂，但是最后可以近似成一个椭圆公式，当椭圆在变大，说明变化值在变大，也就是灰度值在变大。</p>
<p>当图像中一个部分出现密集的角点，要做一个NMS非极大值抑制，留下真正的角点。</p>
<p>&nbsp;</p>
<h2 id='2opencv实现角点检测'>2.Opencv实现角点检测</h2>
<p><code>cv2.cornerHarris(img,blockSize,ksize,k)</code></p>
<ul>
<li>img:要求数据类型为float32</li>
<li>blockSize:角点检测区域的大小</li>
<li>ksize:sobel求导中使用的窗口大小</li>
<li>k：取值参数为[0.04,0.06]</li>

</ul>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20240124135248701.png" referrerpolicy="no-referrer" alt="image-20240124135248701"></p>
<pre><code class='language-python' lang='python'>img = cv2.imread(&quot;C:/Users/Lenovo/Desktop/pictures/shjd.jpg&quot;, cv2.IMREAD_COLOR)

gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
gray = np.float32(gray)

dst = cv2.cornerHarris(gray, 2, 3, 0.04)

img[dst &gt; 0.01 * dst.max()] = [0, 0, 255]

cv_show(&#39;dst&#39;,img)
</code></pre>
<p>&nbsp;</p>
</body>
</html>